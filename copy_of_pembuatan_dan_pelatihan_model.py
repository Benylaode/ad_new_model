# -*- coding: utf-8 -*-
"""Copy of Pembuatan dan Pelatihan Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qPMoG8XHvRLpodS2_h0OYzmXw1Yq5lCp

**Lakukan Import beberapa depedensi yang dibutuhkan**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.multioutput import ClassifierChain
from sklearn.linear_model import LogisticRegression
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline  # Pipeline khusus imblearn (bukan sklearn!)
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MultiLabelBinarizer
from ipywidgets import widgets, VBox, Button, Output
from IPython.display import display
from collections import defaultdict
from imblearn.over_sampling import RandomOverSampler
import joblib

"""**load data hasil ADVERTASING**

Deskripsi Dataset
Dataset ini berisi informasi tentang interaksi pengguna dengan berbagai kampanye iklan digital. Setiap baris mewakili satu interaksi pengguna terhadap suatu iklan dan memuat atribut-atribut berikut:

user_id: ID unik pengguna.

timestamp: Waktu saat interaksi dengan iklan terjadi.

device_type: Jenis perangkat yang digunakan pengguna, seperti Mobile, Desktop, atau Tablet.

location: Lokasi geografis pengguna, seperti USA, UK, Canada, atau negara lain.

age_group: Kelompok usia pengguna, seperti 18-24, 25-34, 35-44, 45-54, dan 55+.

gender: Jenis kelamin pengguna, yaitu Male atau Female.

ad_id: ID unik untuk masing-masing iklan.

content_type: Jenis konten iklan, dapat berupa Text, Image, atau Video.

ad_topic: Topik atau kategori iklan, misalnya Fashion, Electronics, Automotive, dll.

ad_target_audience: Segmentasi target audiens iklan, seperti Tech Enthusiasts, Young Adults, Family Oriented, dan sebagainya.

click_through_rate: Rasio klik terhadap tayangan iklan (CTR).

conversion_rate: Rasio klik yang menghasilkan aksi (misalnya pembelian atau pendaftaran).

engagement_level: Tingkat interaksi pengguna dengan iklan, seperti Liked, Shared, atau Commented.

view_time: Lama waktu (dalam detik) pengguna melihat iklan.

cost_per_click: Biaya yang dibayar pengiklan per klik yang diperoleh.

click_through_rate.1: Duplikat dari click_through_rate (kemungkinan hasil transformasi data, bisa dibersihkan).

conversion_rate.1: Duplikat dari conversion_rate (kemungkinan hasil transformasi data, bisa dibersihkan).

ROI_Category: Kategori Return on Investment (ROI), seperti Low, Medium, atau High.

calculated_ROI: Nilai ROI yang dihitung dari rasio antara conversion_rate dan cost_per_click atau metrik lainnya.

Performance: Kategori performa keseluruhan iklan dalam interaksi tersebut, dengan label seperti Low, Medium, dan High.

cell ini melihat bagian head dari dataset yang ada sembari memperhatiakn kondisi dari atributnya
"""

df = pd.read_csv("Advertising_dataset_with_Performance_Label.csv")
print(df.head())

"""metode di atas saya lakukan di exel sehingga menghasilan data baru yang saya gunakan untuk pelatihan

**MENCOBA SEDIKIT MELAKUKAN DATA UNDERSATANDING**

cell ini melihat bagaimana sebaran model dan mengetahui tipe data pada setiap colom
"""

df.info()

"""memakai fungsi visualisasi setiap data kategorikal"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def visualisasi_kolom(df, nama_kolom):
    if df[nama_kolom].dtype != 'object':
        df[nama_kolom] = df[nama_kolom].astype(str)


    df = df.explode(nama_kolom)
    top_n = 15
    Spend_Amount_counts = df[nama_kolom].value_counts().head(top_n).reset_index()
    Spend_Amount_counts.columns = [nama_kolom, 'Count']

    Spend_Amount_counts = Spend_Amount_counts.sort_values('Count', ascending=False)

    plt.figure(figsize=(12, 8))
    sns.set_style("whitegrid")

    bar_plot = sns.barplot(
        x='Count',
        y=nama_kolom,
        data=Spend_Amount_counts,
        palette='viridis',
        alpha=0.7
    )

    for i, (value, name) in enumerate(zip(Spend_Amount_counts['Count'], Spend_Amount_counts[nama_kolom])):
        bar_plot.text(value + 0.5, i, f'{value}', ha='left', va='center', fontsize=10)

    plt.title(f'jumlah nilai unik dari data {nama_kolom}',
              fontsize=16, pad=20, fontweight='bold')
    plt.xlabel('Number of Titles', fontsize=12)
    plt.ylabel(nama_kolom, fontsize=12)
    plt.xlim(0, Spend_Amount_counts['Count'].max() * 1.1)
    sns.despine(left=True, bottom=True)

    plt.tight_layout()
    plt.show()

"""mencoba memisahkan data kategorikalnya"""

categorical_list = [
     "device_type",
     "location",
     "age_group",
     "gender",
     "content_type",
     "ad_topic",
     "ad_target_audience",
     "engagement_level",
     "Performance",
]

"""melihat persebaran pada semua data kategorikal apakah ada yang tidak seimbang"""

for column in categorical_list:
    visualisasi_kolom(df, column)

"""hasilnya menunjukan data cukup tersebar merata untuk kategorikalnnya

**mencoba melihat bagaiman dengan data numerical**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def visualisasi_numerikal(df, nama_kolom):

    if nama_kolom not in df.columns:
        print(f"Kolom '{nama_kolom}' tidak ada dalam DataFrame.")
        return

    if df[nama_kolom].dtype == 'object':
        print(f"Kolom '{nama_kolom}' bukan tipe data numerikal.")
        return

    plt.figure(figsize=(10, 6))
    sns.set_style("whitegrid")

    sns.histplot(data=df, x=nama_kolom, kde=True, color='skyblue', bins=30) # Adjust bins as needed

    plt.title(f'Distribusi Data: {nama_kolom}', fontsize=16, pad=20, fontweight='bold')
    plt.xlabel(nama_kolom, fontsize=12)
    plt.ylabel('Frekuensi', fontsize=12)
    sns.despine(left=True, bottom=True)

    plt.tight_layout()
    plt.show()

numerical_columns_list = df.select_dtypes(include=np.number).columns.tolist()

for column in numerical_columns_list:
    visualisasi_numerikal(df, column)

"""data numerical cenderung bagis dengan persebran yang baik kecuali untuk kolom calculated_ROi

data di atas adalah data yang melihat hasil performa dari 1000 iklan yang ada dengana melihat perkembangan performa dari masing-masing iklan dengan berbagai kategori dan sasaran audience

**melakukan  pembersihan**

1. langkah pertama adalah mengecek nilai null/nan
"""

for column in df.columns:
    num_null_nan = df[column].isnull().sum()
    print(f"There are {num_null_nan} null/NaN values in the '{column}' column.")

"""nampaknya tidak ada nilai null/nan yang di temukan jadi data aman untuk kategori ini

2. Langkah dua adalah dengan melihat oulayer di data kolom numerikdengan menggunakan boxplot
"""

def boxplot_numeric(df, numeric_cols):
  n_cols = 3
  n_rows = len(numerical_columns_list) // n_cols + 1

  plt.figure(figsize=(15, 5*n_rows))

  for i, col in enumerate(numerical_columns_list, 1):
      if not df[col].isna().all():
          plt.subplot(n_rows, n_cols, i)
          sns.boxplot(y=df[col], color='skyblue')
          plt.title(f'Boxplot of {col}', fontsize=12)
          plt.ylabel('Values')
          sns.despine(left=True)

  plt.tight_layout()
  plt.show()

boxplot_numeric(df, numerical_columns_list)

"""nampaknya bagian calculated_ROI memiliki sedikit banyak outlayer

karena data hanya data dari kolom calculate_ROI yang memiliki banyak data outlayer maka itu saja yang akan kita atasi

menggunakan metode Q1 dan Q3 untuk memotong data
"""

Q1 = df["calculated_ROI"].quantile(0.25)
Q3 = df["calculated_ROI"].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df = df[
    (df["calculated_ROI"] >= lower_bound) &
    (df["calculated_ROI"] <= upper_bound)
]

from scipy.stats.mstats import winsorize
df["calculated_ROI"] = winsorize(df["calculated_ROI"], limits=[0.1, 0.1])

boxplot_numeric(df, numerical_columns_list)

"""nampaknya data yang outlayer sudah di bersihkan

3. Langkah tiga adalah dengan mengecek duplikatnya
"""

df.duplicated().sum()

"""nampaknya tidak ada duplikat yang berlebihan d sini

**medeteksi kategorikal dan menyesuikan one-hot encoding pada data categorical**

nampaknya timestamp masih berbentuk string kategorikal maka kita ubah menjadi tipe datetime
"""

df['timestamp'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %H:%M')

"""melakukan sedikit penyesuain dengan menyamakan seluruh kolom ke huruf kecil"""

for column in categorical_list:
    df[column] = df[column].str.lower()

"""melihat kembali nilai kategorikal pada semua kolom kategorikal dengan semua data kategorikal"""

df["Performance"].unique()

for column in categorical_list:
    print(df[column].unique())

import pandas as pd
import numpy as np

categorical_list = [
     "device_type",
     "location",
     "age_group",
     "gender",
     "content_type",
     "ad_topic",
     "ad_target_audience",
     "engagement_level",
     "Performance",
]


def split_and_clean(value):
    if pd.isna(value):
        return []
    if isinstance(value, str):
        value = value.lower()
        separators = ['|', '/', ',', '&', ';', '\\']
        for sep in separators:
            value = value.replace(sep, ',')
        return [v.strip() for v in value.split(',') if v.strip()]
    else:
        return [str(value).strip().lower()]

def split_klasifikasi(value):
    if pd.isna(value):
        return []
    if isinstance(value, str):
        separators = ['|', '/', ',', '&', ';', '\\']
        for sep in separators:
            value = value.replace(sep, ',')
        return [int(v.strip()) for v in value.split(',') if v.strip().isdigit()]
    elif isinstance(value, (list, np.ndarray)):
        return [int(v) for v in value]
    else:
        return [int(value)]

options_dict = {}

encoded_df = pd.DataFrame(index=df.index)

for column in categorical_list:
    all_values = df[column].apply(split_and_clean)
    unique_labels = sorted(set(label for sublist in all_values for label in sublist))
    options_dict[column] = unique_labels

    for label in unique_labels:
        encoded_df[f"{column}__{label}"] = all_values.apply(lambda x: int(label in x))

klasifikasi_values = df["Performance"].apply(split_klasifikasi)
unique_klasifikasis = sorted(set(c for sublist in klasifikasi_values for c in sublist))

for klasifikasi in unique_klasifikasis:
    encoded_df[f"Performance__{klasifikasi}"] = klasifikasi_values.apply(lambda x: int(klasifikasi in x))


print("Label unik dalam 'Performance':", unique_klasifikasis)

print(df.isnull().sum())

numerical_columns_list = df.select_dtypes(include=np.number).columns.tolist()

encoded_df[numerical_columns_list] = df[numerical_columns_list].fillna(0)

"""**menampilakan data hasil encoding**"""

encoded_df.info()

"""**drop user_id karena tidak relevan untuk prediksi**"""

encoded_df.drop(columns=["user_id"], inplace=True)

encoded_df.info()

encoded_df = encoded_df.sample(frac=1, random_state=42).reset_index(drop=True)

split_index = int(0.8 * len(encoded_df))

df_train = encoded_df[:split_index]
df_test = encoded_df[split_index:]

"""**melakukan split data untuk pelatihan model secara terpisah**"""

encoded_df_low = df_train.drop(columns=["Performance__high", "Performance__medium"])
encoded_df_medium = df_train.drop(columns=["Performance__high", "Performance__low"])
encoded_df_high = df_train.drop(columns=["Performance__medium", "Performance__low"])

"""**model_0**

medefinisikan nilai x dan y untuk pelatihan model
"""

X = encoded_df_low.drop(columns="Performance__low")
y = encoded_df_low['Performance__low']

"""melakukan Undersampel"""

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)

print("Distribusi kelas asli:", Counter(y))

"""split data latih dan test"""

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

"""menggunakan random forest"""

base_model_low = RandomForestClassifier(n_estimators=100, random_state=42)
base_model_low.fit(X_train, y_train)

"""melakukan prediksi dengan model dari data test"""

y_pred = base_model_low.predict(X_test)

"""melihat akurasu"""

accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model 0: {accuracy}")

"""melihat cm dari hasil data test"""

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))  # Atur ukuran gambar
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['0', '1'], yticklabels=['0', '1'])  # Ganti label jika perlu
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Model 0')
plt.show()

"""**model 1**

mnedefinisikan lagi x ddan y untuk model lain
"""

X = encoded_df_medium.drop(columns="Performance__medium")
y = encoded_df_medium['Performance__medium']

"""kali ini mencoba oversampel"""

ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

print("Distribusi kelas asli:", Counter(y_resampled))

"""melakukan split lagi untuk model baru"""

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

"""kembali menggunakan random forst"""

base_model_medium = RandomForestClassifier(n_estimators=100, random_state=42)
base_model_medium.fit(X_train, y_train)

"""melakukan prediksi dengan model baru dalam kasus ini model medium"""

y_pred = base_model_medium.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model 1: {accuracy}")

"""melakukan pengecekan cm nya"""

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))  # Atur ukuran gambar
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['0', '1'], yticklabels=['0', '1'])  # Ganti label jika perlu
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Model 1')
plt.show()

"""**model 2**

mendefinisikan lagi data x dan y nya
"""

X = encoded_df_high.drop(columns="Performance__high") # Ganti dengan kolom fitur Anda
y = encoded_df_high['Performance__high']  # Ganti dengan kolom target Anda

"""mencoba undersampel lagi"""

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)

print("Distribusi kelas asli:", Counter(y_resampled))

"""split dataset lagi"""

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

"""melakukan permodelna dengan logistik regresion kali ini"""

base_model_high = LogisticRegression(solver='lbfgs', max_iter=1000)
base_model_high.fit(X_train, y_train)

"""melihat prediksi lagi"""

y_pred = base_model_high.predict(X_test)

"""melihat hasil akurasi dari prediksi"""

accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model 2: {accuracy}")

"""memantau cm dari data nya"""

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))  # Atur ukuran gambar
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['0', '1'], yticklabels=['0', '1'])  # Ganti label jika perlu
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Model 2')
plt.show()

"""**mengabungkan model**

melihat data yang akan digunaka untuk testing
"""

df_test

"""**melakukan uji pada gabungan model**

sekarang mempersipakan data testing dengan menghilangkan kolom label
"""

y_true = df_test[["Performance__low","Performance__medium", 'Performance__high']].values

"""melakuakn prediksi dengan model low, medium, dan high"""

y_pred_0 = base_model_low.predict(df_test.drop(columns=["Performance__medium", "Performance__low", 'Performance__high']))
y_pred_1 = base_model_medium.predict(df_test.drop(columns=["Performance__medium", "Performance__low", 'Performance__high']))
y_pred_2 = base_model_high.predict(df_test.drop(columns=["Performance__medium", "Performance__low", 'Performance__high']))

y_pred = np.column_stack((y_pred_0, y_pred_1, y_pred_2))

y_pred = [[int(val) for val in row] for row in y_pred]

"""setelah mendapat data hasil testing dalam bentuk list seperti ini [1,0,0] maka akan di ubah menjadi nilai 0 = sama dengan medium dan begitu seterusnya hal ini dilakukan di bawah dengan np.argnmax"""

import numpy as np

y_true_real = np.argmax(y_true, axis=1)
y_pred_real = np.argmax(y_pred, axis=1)

print(y_true_real)

"""melihat metrik akurasi dan cm(confuliosional matriks) nya"""

accuracy = accuracy_score(y_true_real, y_pred_real)
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
f1 = f1_score(y_true, y_pred, average='weighted')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


cm = confusion_matrix(y_true_real, y_pred_real)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""**save model input**

save model untuk dilakukan di aplikasi
"""

joblib.dump(base_model_low, 'base_model_0.pkl')


joblib.dump(base_model_medium, 'base_model_1.pkl')


joblib.dump(base_model_high, 'base_model_2.pkl')

"""**mencoba melakukan uji coba bisa juga di lihat di app.py**"""

# all_columns = encoded_df.drop(columns=['Cluster__0', 'Cluster__1', 'Cluster__2']).columns.tolist()
# print(all_columns)

# grouped_features = defaultdict(list)
# for f in all_columns:
#     if '__' in f:
#         key, val = f.split('__', 1)
#         grouped_features[key.strip()].append(val.strip())

# # Menampilkan hasil
# for k, v in grouped_features.items():
#     print(f"{k} ({len(v)} items):")
#     print(v)
#     print()

# opsi_apm =  grouped_features["Ad Placement Method"]
# opsi_type_of_media = grouped_features["Type of Media (MOECM)"]
# opsi_outlet_channel = grouped_features["Outlet Channel (Agency submission)"]
# opsi_language = grouped_features["Language"]
# opsi_purpose = grouped_features["Purpose"]

# for i in range(len(opsi_apm)):
#      print(f"{i+1}. {opsi_apm[i]}")
# Ad_Placement_Method = input("Ad Placement Method: ")
# a = f"Ad Placement Method__{Ad_Placement_Method.lower()}"
# for i in range(len(opsi_type_of_media)):
#      print(f"{i+1}. {opsi_type_of_media[i]}")
# Type_of_Media = input("Type of Media (MOECM): ")
# b = f"Type of Media (MOECM)__{Type_of_Media.lower()}"
# for i in range(len(opsi_outlet_channel)):
#      print(f"{i+1}. {opsi_outlet_channel[i]}")
# Outlet_Channel = input("Outlet Channel (Agency submission): ")
# c = f"Outlet Channel (Agency submission)__{Outlet_Channel.lower()}"
# for i in range(len(opsi_language)):
#      print(f"{i+1}. {opsi_language[i]}")
# Language = input("Language: ")
# d = f"Language__{Language.lower()}"
# for i in range(len(opsi_purpose)):
#      print(f"{i+1}. {opsi_purpose[i]}")
# Purpose = input("Purpose: ")
# e = f"Purpose__{Purpose.lower()}"
# Spend_Amount = input("Spend Amount: ")

# selected_features = {a, b, c, d, e}
# feature = [1 if i in selected_features else 0 for i in all_columns]

# print(Spend_Amount)

# feature[-1] = (float(Spend_Amount))

# feature_list = []
# feature_list.append(feature)

# print(feature_list)

# len(all_columns)

# len(feature_list[0])

# X_input = np.array(feature_list)

# print(X_input)

# y_pred_0 = base_model_0.predict(X_input)
# y_pred_1 = base_model_1.predict(X_input)
# y_pred_2 = base_model_2.predict(X_input)

# # Gabungkan hasil prediksi menjadi multi-label
# y_pred = np.column_stack((y_pred_0, y_pred_1, y_pred_2))

# # Konversi ke list of lists of int
# y_pred = [[int(val) for val in row] for row in y_pred]

# y_pred_ku = np.argmax(y_pred, axis=1)

# print(y_pred_ku)